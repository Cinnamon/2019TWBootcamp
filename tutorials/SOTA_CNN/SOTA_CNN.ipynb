{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總參數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_params():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        shape = variable.get_shape()\n",
    "        # print(shape)\n",
    "        # print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            # print(dim)\n",
    "            variable_parameters *= dim.value\n",
    "        # print(variable_parameters)\n",
    "        total_parameters += variable_parameters\n",
    "    return total_parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](第四課CNN模型/inception_module.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def Inception(input_data, input_depth=192):\n",
    "    with tf.name_scope('Branch_1'):\n",
    "        X_1 = tf.layers.conv2d(input_data, 64, (1,1))\n",
    "        X_1 = tf.layers.batch_normalization(X_1)\n",
    "        X_1 = tf.nn.leaky_relu(X_1)\n",
    "        \n",
    "    with tf.name_scope('Branch_2'): \n",
    "        X_2 = tf.layers.conv2d(input_data, 96, (1,1))\n",
    "        X_2 = tf.layers.batch_normalization(X_2)\n",
    "        X_2 = tf.nn.leaky_relu(X_2)\n",
    "        \n",
    "        X_2 = tf.layers.conv2d(X_2, 128, (3,3), padding='same')\n",
    "        X_2 = tf.layers.batch_normalization(X_2)\n",
    "        X_2 = tf.nn.leaky_relu(X_2)\n",
    "        \n",
    "    with tf.name_scope('Branch_3'): \n",
    "        X_3 = tf.layers.conv2d(input_data, 16, (1,1))\n",
    "        X_3 = tf.layers.batch_normalization(X_3)\n",
    "        X_3 = tf.nn.leaky_relu(X_3)\n",
    "        \n",
    "        X_3 = tf.layers.conv2d(X_3, 48, (3,3), padding='same')\n",
    "        X_3 = tf.layers.batch_normalization(X_3)\n",
    "        X_3 = tf.nn.leaky_relu(X_3)\n",
    "\n",
    "        X_3 = tf.layers.conv2d(X_3, 32, (5,5), padding='same')\n",
    "        X_3 = tf.layers.batch_normalization(X_3)\n",
    "        X_3 = tf.nn.leaky_relu(X_3)\n",
    "\n",
    "    with tf.name_scope('Branch_4'): \n",
    "        X_4 = tf.layers.max_pooling2d(input_data, 2, 1, padding='same')\n",
    "        X_4 = tf.layers.batch_normalization(X_4)\n",
    "        X_4 = tf.nn.leaky_relu(X_4)\n",
    "        \n",
    "        X_4 = tf.layers.conv2d(X_4, 32, (1,1), padding='same')\n",
    "        X_4 = tf.layers.batch_normalization(X_3)\n",
    "        X_4 = tf.nn.leaky_relu(X_3)\n",
    "\n",
    "    out = tf.concat((X_1,X_2,X_3,X_4), axis=3)\n",
    "\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat:0\", shape=(?, 32, 32, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 32, 32, 192])\n",
    "out=Inception(inputs, input_depth=192)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](第四課CNN模型/殘差結構.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Residual_Block(input_data, in_channel, out_channel, s = 1):\n",
    "    X_shortcut = input_data##記住輸入\n",
    "    X = tf.layers.conv2d(input_data, out_channel, (1, 1), strides = (s,s))\n",
    "    X = tf.layers.batch_normalization(X)\n",
    "    X = tf.nn.relu(X)\n",
    "\n",
    "    X = tf.layers.conv2d(X,out_channel, (3, 3), padding='same', strides = (s,s))\n",
    "    X = tf.layers.batch_normalization(X)\n",
    "    X = tf.nn.relu(X)\n",
    "\n",
    "    X = tf.layers.conv2d(X,out_channel, (1,1), strides = (1, 1), )\n",
    "    X = tf.layers.batch_normalization(X)\n",
    "    \n",
    "    if (in_channel != out_channel):\n",
    "        X_shortcut = tf.layers.conv2d(X_shortcut, out_channel, (1,1),)\n",
    "        X_shortcut = tf.layers.batch_normalization(X)\n",
    "\n",
    "    X = X+X_shortcut\n",
    "    X = tf.nn.relu(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_2:0\", shape=(?, 32, 32, 192), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 32, 32, 192])\n",
    "out= Residual_Block(inputs, 192, 192, s = 1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depthwise Seperable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](第四課CNN模型/Densenet_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792\n",
      "283\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "##一般卷積\n",
    "tf.reset_default_graph() \n",
    "inputs = tf.placeholder(tf.float32, [None, 300, 300, 3])\n",
    "X = tf.layers.conv2d(inputs, 64, (3,3), strides=(1,1), activation=tf.nn.leaky_relu)\n",
    "print(get_num_params()) ##  (3*3*3+1)*64=1792\n",
    "\n",
    "##Depthwise separable 卷積\n",
    "tf.reset_default_graph() \n",
    "inputs = tf.placeholder(tf.float32, [None, 300, 300, 3])\n",
    "X = tf.layers.separable_conv2d(inputs, 64, (3,3), padding='SAME')\n",
    "print(get_num_params()) ## 3*3*3+(1*1*3+1)*64=283"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depthwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib as tc\n",
    "\n",
    "slim = tc.slim\n",
    "\n",
    "tf.reset_default_graph()\n",
    "##單獨定義 depthwise_conv層\n",
    "## 參考 https://github.com/TropComplique/shufflenet-v2-tensorflow/blob/master/architecture.py\n",
    "def depthwise_conv(\n",
    "        x, kernel=3, stride=1, padding='SAME',\n",
    "        activation_fn=None, normalizer_fn=None,\n",
    "        weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        data_format='NHWC', scope='depthwise_conv'):\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        assert data_format == 'NHWC'\n",
    "        in_channels = x.shape[3].value\n",
    "        W = tf.get_variable(\n",
    "            'depthwise_weights',\n",
    "            [kernel, kernel, in_channels, 1], dtype=tf.float32,\n",
    "            initializer=weights_initializer\n",
    "        )\n",
    "        x = tf.nn.depthwise_conv2d(x, W, [1, stride, stride, 1], padding, data_format='NHWC')\n",
    "        x = normalizer_fn(x) if normalizer_fn is not None else x  # batch normalization\n",
    "        x = activation_fn(x) if activation_fn is not None else x  # nonlinearity\n",
    "        return x\n",
    "      \n",
    "inputs = tf.placeholder(tf.float32, [None, 300, 300, 3])\n",
    "out=depthwise_conv(\n",
    "        inputs, kernel=3, stride=1, padding='SAME',\n",
    "        activation_fn=None, normalizer_fn=None,\n",
    "        weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        data_format='NHWC', scope='depthwise_conv')\n",
    "print(get_num_params()) ## 3*3*3=27  \n",
    "\n",
    "\n",
    "##運用slim更簡單\n",
    "def depthwise_conv_bn(x, kernel_size, stride=1, dilation=1):\n",
    "    with tf.variable_scope(None, 'depthwise_conv_bn'):\n",
    "        x = slim.separable_conv2d(x, None, kernel_size, depth_multiplier=1, stride=stride,\n",
    "                                  rate=dilation,)\n",
    "        #x = slim.batch_norm(x, activation_fn=None, fused=False)\n",
    "    return x\n",
    "  \n",
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 300, 300, 3])\n",
    "out = depthwise_conv_bn(inputs, (3,3), stride=1, dilation=1)\n",
    "print(get_num_params()) ## 3*3*3+3=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResnetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](第四課CNN模型/ResnetV2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResentV2_block(input_data, input_depth, compress_depth, output_depth, strides=(1,1)):\n",
    "    X_shortcut = input_data\n",
    "    X = tf.layers.conv2d(input_data, compress_depth, (1,1)) ##先壓縮\n",
    "    X = tf.layers.batch_normalization(X)\n",
    "    X = tf.nn.leaky_relu(X)\n",
    "    X = tf.layers.conv2d(X,compress_depth, (3,3), padding='same', strides=strides)\n",
    "    X = tf.layers.batch_normalization(X)\n",
    "    X = tf.nn.leaky_relu(X)\n",
    "    X = tf.layers.conv2d(X, output_depth, (1,1)) ##再放大\n",
    "    if (input_depth != output_depth):\n",
    "        X_shortcut = tf.layers.conv2d(X_shortcut, output_depth, (1,1), strides=strides, padding='same') ##深度不同\n",
    "    if (input_depth == output_depth) & (strides !=(1,1)):\n",
    "        X_shortcut = tf.image.resize_images(X_shortcut, (X.shape[1], X.shape[2]), method=0) ##Size不同\n",
    "    out = X_shortcut+X\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(?, 32, 32, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 64, 64, 128])\n",
    "out=ResentV2_block(inputs,128,64,256,strides=(2,2))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception-ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](第四課CNN模型/Inception-Resnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionResentA_block(input_data, input_depth=3, output_depth=384):\n",
    "    X_shortcut=input_data\n",
    "    with tf.name_scope('Branch_1'):\n",
    "        X_1 = tf.layers.conv2d(input_data, 32, (1,1))\n",
    "        X_1 = tf.layers.batch_normalization(X_1)\n",
    "        X_1 = tf.nn.leaky_relu(X_1)\n",
    "        \n",
    "    with tf.name_scope('Branch_2'): \n",
    "        X_2 = tf.layers.conv2d(input_data, 32, (1,1))\n",
    "        X_2 = tf.layers.batch_normalization(X_2)\n",
    "        X_2 = tf.nn.leaky_relu(X_2)\n",
    "        \n",
    "        X_2 = tf.layers.conv2d(X_2,32,(3,3), padding='same')\n",
    "        X_2 = tf.layers.batch_normalization(X_2)\n",
    "        X_2 = tf.nn.leaky_relu(X_2)\n",
    "        \n",
    "    with tf.name_scope('Branch_3'): \n",
    "        X_3 = tf.layers.conv2d(input_data, 32, (1,1))\n",
    "        X_3 = tf.layers.batch_normalization(X_3)\n",
    "        X_3 = tf.nn.leaky_relu(X_3)\n",
    "        \n",
    "        X_3 = tf.layers.conv2d(X_3, 48, (3,3), padding='same')\n",
    "        X_3 = tf.layers.batch_normalization(X_3)\n",
    "        X_3 = tf.nn.leaky_relu(X_3)\n",
    "\n",
    "        X_3 = tf.layers.conv2d(X_3, 64, (3,3), padding='same')\n",
    "        X_3 = tf.layers.batch_normalization(X_3)\n",
    "        X_3 = tf.nn.leaky_relu(X_3)\n",
    "    out = tf.concat((X_1,X_2,X_3), axis=3)\n",
    "\n",
    "    out = tf.layers.conv2d(out, output_depth, (1,1))\n",
    "\n",
    "    if (input_depth != output_depth):\n",
    "        X_shortcut=tf.layers.conv2d(X_shortcut, output_depth, (1,1))\n",
    "\n",
    "    out = X_shortcut+out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(?, 64, 64, 384), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 64, 64, 3])\n",
    "out=InceptionResentA_block(inputs,input_depth=3,output_depth=384)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dense_Stage(inputs_,depth=64,repeat=8):\n",
    "    for _ in range(repeat):\n",
    "        X_input=inputs_\n",
    "        X=tf.layers.conv2d(inputs_,depth,(1,1),strides=(1,1),activation=tf.nn.leaky_relu)\n",
    "        X=tf.layers.batch_normalization(X)\n",
    "        X=tf.layers.separable_conv2d(X,depth,(3,3),padding='SAME')\n",
    "        X=tf.nn.leaky_relu(X)\n",
    "        X=tf.layers.batch_normalization(X)\n",
    "        X=tf.concat([X_input,X],3)\n",
    "        inputs_=X\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat_7:0\", shape=(?, 64, 64, 515), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 64, 64, 3])\n",
    "out=Dense_Stage(inputs,depth=64,repeat=8)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shufflenetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](第四課CNN模型/Shufflenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "##參考：https://github.com/timctho/shufflenet-v2-tensorflow/blob/master/module.py\n",
    "##參考：https://github.com/TropComplique/shufflenet-v2-tensorflow/blob/master/architecture.py\n",
    "\n",
    "def shuffle_unit(x, groups):  ##一般的shuffle depthwise_conv輸出的Feature Map\n",
    "    with tf.variable_scope('shuffle_unit'):\n",
    "        n, h, w, c = x.get_shape().as_list()\n",
    "        x = tf.reshape(x, shape=([tf.shape(x)[0], h, w, groups, c // groups]))\n",
    "        x = tf.transpose(x, tf.convert_to_tensor([0, 1, 2, 4, 3]))\n",
    "        x = tf.reshape(x, shape=[tf.shape(x)[0], h, w, c])\n",
    "    return x\n",
    "def depthwise_conv(\n",
    "        x, kernel=3, stride=1, padding='SAME',\n",
    "        activation_fn=None, normalizer_fn=None,\n",
    "        weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        data_format='NHWC', scope='depthwise_conv'):      ##一般的depthwise_conv\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        assert data_format == 'NHWC'\n",
    "        in_channels = x.shape[3].value\n",
    "        W = tf.get_variable(\n",
    "            'depthwise_weights',\n",
    "            [kernel, kernel, in_channels, 1], dtype=tf.float32,\n",
    "            initializer=weights_initializer\n",
    "        )\n",
    "        x = tf.nn.depthwise_conv2d(x, W, [1, stride, stride, 1], padding, data_format='NHWC')\n",
    "        x = tf.layers.batch_normalization(x) if normalizer_fn is not None else x  # batch normalization\n",
    "        x = tf.nn.leaky_relu(x) if activation_fn is not None else x  # nonlinearity\n",
    "        return x\n",
    "    \n",
    "def conv_bn_relu(x, out_channel, kernel_size, stride=1):  ##一般的Convolution+BN+Relu\n",
    "    with tf.variable_scope(None, 'conv_bn_relu'):\n",
    "        x = tf.layers.conv2d(x, out_channel, kernel_size, stride,)\n",
    "        x = tf.nn.leaky_relu(tf.layers.batch_normalization(x))\n",
    "    return x\n",
    "\n",
    "def shufflenet_v2_block(x, out_channel, kernel_size, stride=1, shuffle_group=2): ##shufflenet_v2_block\n",
    "    with tf.variable_scope(None, 'shuffle_v2_block'):\n",
    "        if stride == 1:\n",
    "            top, bottom = tf.split(x, num_or_size_splits=2, axis=3)\n",
    "\n",
    "            half_channel = out_channel // 2\n",
    "\n",
    "            top = conv_bn_relu(top, half_channel, 1)\n",
    "            top = depthwise_conv_bn(top, kernel_size, stride)\n",
    "            top = conv_bn_relu(top, half_channel, 1)\n",
    "\n",
    "            out = tf.concat([top, bottom], axis=3)\n",
    "            out = shuffle_unit(out, shuffle_group)\n",
    "\n",
    "        else:   ##downsampling的Block\n",
    "            half_channel = out_channel // 2\n",
    "            b0 = conv_bn_relu(x, half_channel, 1)\n",
    "            b0 = depthwise_conv_bn(b0, kernel_size, stride)\n",
    "            b0 = conv_bn_relu(b0, half_channel, 1)\n",
    "\n",
    "            b1 = depthwise_conv_bn(x, kernel_size, stride)\n",
    "            b1 = conv_bn_relu(b1, half_channel, 1)\n",
    "\n",
    "            out = tf.concat([b0, b1], axis=3)\n",
    "            out = shuffle_unit(out, shuffle_group)\n",
    "        return out\n",
    "\n",
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 300, 300, 4])\n",
    "out=shufflenet_v2_block(inputs, 2, (3,3), stride=1, shuffle_group=2)\n",
    "print(get_num_params()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobilenetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](第四課CNN模型/MobilenetV2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthwise_conv(\n",
    "        x, kernel=3, stride=1, padding='SAME',\n",
    "        activation_fn=None, normalizer_fn=None,\n",
    "        weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        data_format='NHWC', scope='depthwise_conv'):      ##一般的depthwise_conv\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        assert data_format == 'NHWC'\n",
    "        in_channels = x.shape[3].value\n",
    "        W = tf.get_variable(\n",
    "            'depthwise_weights',\n",
    "            [kernel, kernel, in_channels, 1], dtype=tf.float32,\n",
    "            initializer=weights_initializer\n",
    "        )\n",
    "        x = tf.nn.depthwise_conv2d(x, W, [1, stride, stride, 1], padding, data_format='NHWC')\n",
    "        x = tf.layers.batch_normalization(x) if normalizer_fn is not None else x  # batch normalization\n",
    "        x = tf.nn.leaky_relu(x) if activation_fn is not None else x  # nonlinearity\n",
    "        return x\n",
    "\n",
    "\n",
    "def res_block(input, expansion_ratio, output_dim, stride, name, bias=False, shortcut=True):\n",
    "    with tf.name_scope(name), tf.variable_scope(name):\n",
    "        # pw\n",
    "        bottleneck_dim=round(expansion_ratio*input.get_shape().as_list()[-1]) \n",
    "        net = tf.layers.conv2d(input, bottleneck_dim,(1,1), name='pw', \n",
    "                               kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003),use_bias=bias) ##先擴張\n",
    "        net = tf.layers.batch_normalization(net, name='pw_bn')\n",
    "        net = tf.nn.relu6(net)\n",
    "        # dw\n",
    "        net = depthwise_conv(net)\n",
    "        net = tf.layers.batch_normalization(net, name='dw_bn')\n",
    "        net = tf.nn.relu6(net)\n",
    "        # pw & linear\n",
    "        net = tf.layers.conv2d(net, output_dim,(1,1), name='pw_linear', \n",
    "                               kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003),use_bias=bias) ##壓回輸出深度\n",
    "        net = tf.layers.batch_normalization(net,name='pw_linear_bn')\n",
    "\n",
    "        # element wise add, only for stride==1\n",
    "        if shortcut and stride == 1:\n",
    "            in_dim=int(input.get_shape().as_list()[-1])\n",
    "            if in_dim != output_dim:\n",
    "                ins=tf.layers.conv2d(input, output_dim,(1,1), name='ex_dim', \n",
    "                               kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003),use_bias=bias) \n",
    "                net=ins+net\n",
    "            else:\n",
    "                net=input+net\n",
    "\n",
    "        return net\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Res1/Res1/add:0\", shape=(?, 300, 300, 32), dtype=float32)\n",
      "Tensor(\"Res2/Res2/add:0\", shape=(?, 300, 300, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 300, 300, 3])\n",
    "out=res_block(inputs,4,32,1,name='Res1')\n",
    "print(out)\n",
    "out=res_block(out,4,32,1,name='Res2')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MBConvBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](第四課CNN模型/EfficientnetB0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def depthwise_conv(\n",
    "        x, kernel=3, stride=1, padding='SAME',\n",
    "        activation_fn=None, normalizer_fn=None,\n",
    "        weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        data_format='NHWC', scope='depthwise_conv'):      ##一般的depthwise_conv\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        assert data_format == 'NHWC'\n",
    "        in_channels = x.shape[3].value\n",
    "        W = tf.get_variable(\n",
    "            'depthwise_weights',\n",
    "            [kernel, kernel, in_channels, 1], dtype=tf.float32,\n",
    "            initializer=weights_initializer\n",
    "        )\n",
    "        x = tf.nn.depthwise_conv2d(x, W, [1, stride, stride, 1], padding, data_format='NHWC')\n",
    "        x = tf.layers.batch_normalization(x) if normalizer_fn is not None else x  # batch normalization\n",
    "        x = tf.nn.leaky_relu(x) if activation_fn is not None else x  # nonlinearity\n",
    "        return x\n",
    "\n",
    "\n",
    "def MBConvBlock(input, expansion_ratio, output_dim, stride, name,squeeze ,bias=False, shortcut=True,use_Squeeze_Excitation=True):\n",
    "    with tf.name_scope(name), tf.variable_scope(name):\n",
    "        # pw\n",
    "        bottleneck_dim=round(expansion_ratio*input.get_shape().as_list()[-1]) \n",
    "        net = tf.layers.conv2d(input, bottleneck_dim,(1,1), name='pw', \n",
    "                               kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003),use_bias=bias) ##先擴張\n",
    "        net = tf.layers.batch_normalization(net, name='pw_bn')\n",
    "        net = tf.nn.relu6(net)\n",
    "        # dw\n",
    "        net = depthwise_conv(net,stride=stride)\n",
    "        net = tf.layers.batch_normalization(net, name='dw_bn')\n",
    "        net = tf.nn.relu6(net)\n",
    "        # pw & linear\n",
    "        net = tf.layers.conv2d(net, output_dim,(1,1),name='pw_linear', \n",
    "                               kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003),use_bias=bias) ##壓回輸出深度\n",
    "        net = tf.layers.batch_normalization(net,name='pw_linear_bn')\n",
    "        \n",
    "        if use_Squeeze_Excitation:\n",
    "            in_dim=int(net.get_shape().as_list()[-1])\n",
    "            Squeeze=tf.layers.average_pooling2d(net, net.get_shape()[1:-1], 1)\n",
    "            Squeeze=tf.nn.relu(tf.layers.dense(Squeeze, use_bias=False, units=in_dim//squeeze))\n",
    "            Excitation=tf.nn.relu(tf.layers.dense(Squeeze, use_bias=False, units=output_dim))\n",
    "            Excitation=tf.nn.sigmoid(Excitation)\n",
    "            net = tf.reshape(Excitation, [-1,1,1,output_dim])*net\n",
    "\n",
    "        # SENET-Squeeze-Excitation\n",
    "        in_dim=int(input.get_shape().as_list()[-1])\n",
    "        if shortcut and stride == 1:\n",
    "            if in_dim != output_dim:\n",
    "                ins=tf.layers.conv2d(input, output_dim,(1,1), name='ex_dim', \n",
    "                               kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003),use_bias=bias) \n",
    "                net=ins+net\n",
    "            else:\n",
    "                net=input+net\n",
    "\n",
    "        return net\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"first/first/add:0\", shape=(?, 300, 300, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 300, 300, 43])\n",
    "out=MBConvBlock(inputs, 4, 64, 1, 'first', 4,bias=False, shortcut=True,use_Squeeze_Excitation=True)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobilenetV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](第四課CNN模型/MobilenetV3_block.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def Hswish(input_):\n",
    "    return input_* tf.nn.relu6(input_ + 3.) / 6.\n",
    "\n",
    "def Hsigmoid(input_):\n",
    "    return tf.nn.relu6(input_ + 3.) / 6.\n",
    "\n",
    "def depthwise_conv(\n",
    "        x, kernel=3, stride=1, padding='SAME',\n",
    "        activation_fn=None, normalizer_fn=None,\n",
    "        weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        data_format='NHWC', scope='depthwise_conv'):      ##一般的depthwise_conv\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        assert data_format == 'NHWC'\n",
    "        in_channels = x.shape[3].value\n",
    "        W = tf.get_variable(\n",
    "            'depthwise_weights',\n",
    "            [kernel, kernel, in_channels, 1], dtype=tf.float32,\n",
    "            initializer=weights_initializer\n",
    "        )\n",
    "        x = tf.nn.depthwise_conv2d(x, W, [1, stride, stride, 1], padding, data_format='NHWC',)\n",
    "        x = tf.layers.batch_normalization(x) if normalizer_fn is not None else x  # batch normalization\n",
    "        x = tf.nn.leaky_relu(x) if activation_fn is not None else x  # nonlinearity\n",
    "        return x\n",
    "    \n",
    "def SEBlock(input_,squeeze=4):\n",
    "    in_dim=int(input_.get_shape().as_list()[-1])\n",
    "    #print( input_.get_shape()[1:-1])\n",
    "    Squeeze=tf.layers.average_pooling2d(input_, input_.get_shape()[1:-1], 1)\n",
    "    Squeeze=tf.nn.relu(tf.layers.dense(Squeeze, use_bias=False, units=in_dim//squeeze)) \n",
    "    Excitation=tf.nn.relu(tf.layers.dense(Squeeze, use_bias=False, units=in_dim))\n",
    "    Excitation=Hsigmoid(Excitation) ##Hsigmoid replace Sigmoid\n",
    "    Excitation = tf.reshape(Excitation, [-1,1,1,in_dim])\n",
    "    return input_*Excitation\n",
    "    \n",
    "    \n",
    "def MobileV3Bottleneck(input_,expand_size,squeeze,out_size,kernel_size,stride=1,relu=True,se=True):\n",
    "    Shortcut=input_\n",
    "    in_dim=int(input_.get_shape().as_list()[-1])\n",
    "    out=tf.layers.batch_normalization(tf.layers.conv2d(input_,expand_size,(1,1),(1,1),use_bias=False))\n",
    "    if relu:\n",
    "        out=tf.nn.relu(out) #or relu6\n",
    "    else:\n",
    "        out=Hswish(out)\n",
    "        \n",
    "    \n",
    "    out=depthwise_conv(out,kernel=kernel_size,stride=stride, padding='SAME')\n",
    "    out=tf.layers.batch_normalization(out)\n",
    "    if relu:\n",
    "        out=tf.nn.relu(out) #or relu6\n",
    "    else:\n",
    "        out=Hswish(out)\n",
    "        \n",
    "    out=tf.layers.batch_normalization(tf.layers.conv2d(input_,out_size,(1,1),(1,1),use_bias=False))\n",
    "    \n",
    "    if (in_dim != out_size) and (stride == 1):\n",
    "        Shortcut=tf.layers.conv2d(Shortcut,out_size, (1,1), strides = (stride, stride),use_bias=False)\n",
    "        Shortcut = tf.layers.batch_normalization(Shortcut)\n",
    "    if se:\n",
    "        assert squeeze<=out_size\n",
    "        out=SEBlock(out,squeeze=squeeze)\n",
    "\n",
    "    out = out +Shortcut if stride==1 else out\n",
    "    return out\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_3:0\", shape=(?, 300, 300, 112), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 300, 300, 80])\n",
    "out=MobileV3Bottleneck(inputs,480,4,112,3,stride=1,relu=False,se=True)\n",
    "print(out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
